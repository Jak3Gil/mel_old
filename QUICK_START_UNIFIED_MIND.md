# 🚀 Quick Start: Unified Mind System

## ✅ Everything Is Ready!

All tests stopped. System is clean and ready to run.

---

## 🎯 Run the Complete System

### Text Output Only (Recommended):
```bash
cd /Users/jakegilbert/Desktop/Melvin/Melvin
./melvin_unified
```

### With Visual Display:
```bash
# Terminal 1: Main system
./melvin_unified

# Terminal 2: Visual debug window
python3 advanced_attention_display.py
```

---

## 📊 What You'll See

### Terminal Output:
```
🧠 Initializing Unified Melvin Brain...
📂 Loaded existing knowledge: 46 nodes, 72 edges
✅ Camera available via Python

[Frame 100] 🧠 Attention... object_3 (F=0.74)
   A=0.9 R=0.7 N=0.2 T=0.6 C=0.8
   Bias: +0.15 (person)

💭 Melvin: I see object_3 persisting

Knowledge: 47 nodes, 89 edges
```

### Visual Display (if opened):
- **Gray boxes** = All detected regions with scores
- **Yellow box + crosshair** = Current focus
- **Score breakdown**: A, R, N, T, C values
- **Reason**: "high salience, curiosity spike, tracking continuity"
- **Formula**: F = A×0.4 + R×0.3 + N×0.2 + T×0.05 + C×0.05

---

## 🧠 System Features

### ✅ Attention Formula:
- **A** (Salience): Edge intensity + motion
- **R** (Relevance): Center proximity + feedback biases
- **N** (Need): Object size importance
- **T** (Temporal): Tracking persistence
- **C** (Curiosity): Prediction error + novelty

### ✅ Advanced Behaviors:
- **Historical Inertia**: Won't switch unless 15% better
- **Softmax Selection**: Sharp, probabilistic decisions
- **Inhibition of Return**: Doesn't revisit immediately
- **Persistence Bonus**: Tracked objects become sticky
- **Prediction Error**: Unexpected motion → curiosity spike
- **Feedback Biases**: Thoughts influence next perception

### ✅ No Dependencies on:
- ❌ YOLO (pure OpenCV edge detection)
- ❌ Pre-trained models
- ❌ Semantic labels
- ❌ External classification

### ✅ Pure Learning:
- Generic object IDs: `object_0`, `object_1`, etc.
- EXACT edges for co-occurrence
- TEMPORAL edges for sequences
- LEAP synthesis discovers patterns
- Feedback creates meaning

---

## 🎮 Controls

**Main System:**
- Press `Ctrl+C` to stop cleanly
- Auto-saves every 30 seconds

**Visual Display:**
- Press `q` to close window
- Main system keeps running

---

## 📈 Knowledge Growth

### Initial State:
- 23 base concepts (fire, heat, water, sun, person, etc.)
- 19 relationships

### After Running:
- Visual objects added: object_0, object_1, ...
- Co-occurrence edges created
- Temporal sequences formed
- Feedback biases accumulate
- Thoughts reference learned concepts

---

## 🔍 Monitoring

### Real-time Stats:
```
Knowledge: X nodes, Y edges (updated every frame)
```

### After Stopping:
```bash
./inspect_kb  # View full knowledge base
```

---

## 💡 What Makes This Special

### Traditional Vision System:
```
Camera → YOLO → "person" label → Done
```

### Melvin's Unified Mind:
```
Camera → Edge detection → Candidate regions →
Attention formula (with reasoning feedback) →
Select ONE focus → Query memory →
Generate thought → Create biases →
Next perception INFLUENCED by thought →
Continuous meaning-driven learning!
```

---

## 🎓 The Big Idea

**Melvin doesn't just see objects.**  
**He thinks about what he sees.**  
**His thoughts shape what he looks at next.**

This is **unified cognition** - perception and reasoning as one continuous process.

---

## 🚀 Ready to Run!

```bash
./melvin_unified
```

Watch as:
1. ✅ Attention selects focus using weighted formula
2. ✅ Same objects tracked across frames (no duplicates)
3. ✅ Thoughts generated from focused objects
4. ✅ Keywords extracted and fed back
5. ✅ Next frame's attention BIASED by thoughts
6. ✅ Knowledge graph grows continuously

**The unified mind loop is complete!** 🧠🔄✨

Press `Ctrl+C` when done. Knowledge auto-saves.

---

## 📚 Documentation

- `UNIFIED_MIND_ARCHITECTURE.md` - Full technical details
- `RAW_VISION_SYSTEM.md` - Vision implementation
- `melvin/core/attention_manager.h` - Attention algorithm
- `melvin/core/unified_mind.h` - Main cognitive loop

---

**All tests killed. System ready. Start when ready!** ✅

